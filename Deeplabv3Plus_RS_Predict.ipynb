{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9466,
     "status": "ok",
     "timestamp": 1736987859829,
     "user": {
      "displayName": "Zongrong Li",
      "userId": "01886082322528664220"
     },
     "user_tz": 480
    },
    "id": "0fgYf485ioL7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1736988405233,
     "user": {
      "displayName": "Zongrong Li",
      "userId": "01886082322528664220"
     },
     "user_tz": 480
    },
    "id": "_XaEJVYrk3w-",
    "outputId": "f0f11565-9799-4c4a-d730-d9e72e53af0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_30940\\1194378632.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\"./deeplabv3_finetuned_RS_Sen1Flood11_V1.pth\", map_location=device),\n"
     ]
    }
   ],
   "source": [
    "# =============== 1. Preparation of Device, Model, and Transform ===============\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume the number of output classes during training was 9 (including background)\n",
    "num_classes = 9\n",
    "\n",
    "# 1.1 Define the network and load local weights\n",
    "model = deeplabv3_resnet50(num_classes=num_classes)\n",
    "# If you saved only the state_dict, use load_state_dict\n",
    "# If you encounter an error, it may mean the entire model was saved, and you need to use torch.load() instead\n",
    "model.load_state_dict(\n",
    "    torch.load(\"./deeplabv3_finetuned_RS_Sen1Flood11_V1.pth\", map_location=device),\n",
    "    strict=False\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()  # Switch to evaluation mode\n",
    "\n",
    "# 1.2 Define the image transformation for inference (consistent with training)\n",
    "transform = transforms.Compose([\n",
    "    # This is just an example: only converting the image to a Tensor.\n",
    "    # If you performed Resize/Crop/Normalize during training, ensure consistency here\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1736990494337,
     "user": {
      "displayName": "Zongrong Li",
      "userId": "01886082322528664220"
     },
     "user_tz": 480
    },
    "id": "VJwDD8fFisUn"
   },
   "outputs": [],
   "source": [
    "# =============== 2. Specify Input and Output Directories ===============\n",
    "input_dir = \"./s2input\"  # Folder containing images for inference\n",
    "#output_dir = \"./out\"\n",
    "output_dir = \"./s2output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# =============== 3. Define the Color Palette idx2color Corresponding to Your Training ===============\n",
    "# Example: 0=background, 1=Bareland, 2=Rangeland, 3=Developed space, 4=Road,\n",
    "# 5=Tree, 6=Water, 7=Agriculture land, 8=Building\n",
    "idx2color = np.array([\n",
    "    [128, 128, 128],  # Background\n",
    "    [0, 0, 0],  # 1=Bareland\n",
    "    [255, 255, 255],  # 2=Rangeland\n",
    "], dtype=np.uint8)\n",
    "\n",
    "# (Optional) If you need to visualize the legend, you can keep this dictionary:\n",
    "color_mapping = {\n",
    "    \"-1\": [128, 128, 128],\n",
    "    \"0\": [0, 0, 0],\n",
    "    \"1\": [255, 255, 255],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84292,
     "status": "ok",
     "timestamp": 1736990581465,
     "user": {
      "displayName": "Zongrong Li",
      "userId": "01886082322528664220"
     },
     "user_tz": 480
    },
    "id": "VrWOz8QaqfGJ",
    "outputId": "c4856407-7ef6-425b-cab9-0b8d1e57ab5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 0/2 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on: ./s2input\\Sentinel2_SWIR_NIR_Red.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 2/2 [00:00<00:00,  4.16image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predicted segmentation to: ./s2output\\Sentinel2_SWIR_NIR_Red.png\n",
      "Inferencing on: ./s2input\\Sentinel2_TrueColor_RGB.png\n",
      "Saved predicted segmentation to: ./s2output\\Sentinel2_TrueColor_RGB.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# =============== 4. Batch Process All Images in the Specified Folder ===============\n",
    "valid_exts = {\".jpg\", \".png\", \".jpeg\"}\n",
    "\n",
    "# Get a list of valid image files in the input directory\n",
    "image_files = [file_name for file_name in os.listdir(input_dir) if os.path.splitext(file_name)[1].lower() in valid_exts]\n",
    "\n",
    "# Create a progress bar for the list of images\n",
    "for file_name in tqdm(image_files, desc=\"Processing Images\", unit=\"image\"):\n",
    "    img_path = os.path.join(input_dir, file_name)\n",
    "    print(f\"Inferencing on: {img_path}\")\n",
    "\n",
    "    # ============== 4.1. Read and Transform ==============\n",
    "    input_image = Image.open(img_path).convert(\"RGB\")\n",
    "    input_tensor = transform(input_image).unsqueeze(0).to(device)  # shape: [1, 3, H, W]\n",
    "\n",
    "    # ============== 4.2. Forward Inference ==============\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)          # dict: {\"out\": logits, ...}\n",
    "        logits = outputs[\"out\"]               # shape: [1, num_classes, H, W]\n",
    "        pred = logits.argmax(dim=1)           # [1, H, W]\n",
    "        pred = pred.squeeze(0).cpu().numpy()  # (H, W)\n",
    "\n",
    "    # ============== 4.3. Map Prediction to a Colored Image ==============\n",
    "    # Classes outside the defined range are treated as background\n",
    "    pred[pred >= len(idx2color)] = 0\n",
    "    pred_color = idx2color[pred]  # (H, W, 3)\n",
    "    pred_image = Image.fromarray(pred_color)\n",
    "\n",
    "    # ============== 4.4. Save Inference Results to output_dir ==============\n",
    "    save_path = os.path.join(output_dir, file_name)\n",
    "    pred_image.save(save_path)\n",
    "    print(f\"Saved predicted segmentation to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOrEAqaxpMTNpaD1z9y86Bv",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "floodPrj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
